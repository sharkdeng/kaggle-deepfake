{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference Kernel Demo\n",
    "\n",
    "This is the kernel I’ve used for my recent submissions. It takes about 5-6 hours on the test set, using only CPU. \n",
    "\n",
    "I’ve provided this kernel because a lot of people have problems making submissions. This method works and has never errored out for me. (Although I haven't tried making a submission using the GPU yet -- so no guarantees there.)\n",
    "\n",
    "It uses BlazeFace for face extraction (see also [my BlazeFace kernel](https://www.kaggle.com/humananalog/starter-blazeface-pytorch)) and ResNeXt50 as the classifier model.\n",
    "\n",
    "We take the average prediction over 17 frames from each video. (Why 17? Using more frames makes the kernel slower, but doesn't appear to improve the score much. I used an odd number so we don't always land on even frames.)\n",
    "\n",
    "**Please use this kernel only to learn from...** Included is the checkpoint for a ResNeXt50 model that hasn't really been trained very well yet. I'm sure you can improve on it by training your own model!\n",
    "\n",
    "You could use the included trained weights to get yourself an easy top-50 score on the leaderboard (as of 24 Jan 2020) but it’s nicer to use it as a starting point for your own work. :-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import os, sys, time\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image, ImageStat, ImageEnhance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the test videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dir = \"/kaggle/input/deepfake-detection-challenge/test_videos/\"\n",
    "\n",
    "test_videos = sorted([x for x in os.listdir(test_dir) if x[-4:] == \".mp4\"])\n",
    "len(test_videos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 1.3.0\n",
      "CUDA version: 10.0.130\n",
      "cuDNN version: 7603\n"
     ]
    }
   ],
   "source": [
    "print(\"PyTorch version:\", torch.__version__)\n",
    "print(\"CUDA version:\", torch.version.cuda)\n",
    "print(\"cuDNN version:\", torch.backends.cudnn.version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpu = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"/kaggle/input/blazeface-pytorch\")\n",
    "\n",
    "from blazeface import BlazeFace\n",
    "facedet = BlazeFace().to(gpu)\n",
    "facedet.load_weights(\"/kaggle/input/blazeface-pytorch/blazeface.pth\")\n",
    "facedet.load_anchors(\"/kaggle/input/blazeface-pytorch/anchors.npy\")\n",
    "_ = facedet.train(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_frames(path):\n",
    "    v_cap = cv2.VideoCapture(path)\n",
    "    v_int = int(v_cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    if v_int <= 0: return None\n",
    "\n",
    "    frame_idxs = np.linspace(0, v_int - 1, frames_per_vid, endpoint=True, dtype=np.int)\n",
    "\n",
    "    result = []\n",
    "    for i in range(v_int):\n",
    "        ret = v_cap.grab()\n",
    "        if ret is None:\n",
    "            continue\n",
    "            \n",
    "        if i in frame_idxs:\n",
    "            ret, frame = v_cap.retrieve()\n",
    "            if ret is None or frame is None:\n",
    "                continue\n",
    "    \n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            result.append(frame)\n",
    "            \n",
    "    v_cap.release()\n",
    "    return np.array(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaceExtractor:\n",
    "    \n",
    "    def __init__(self, video_read_fn, facedet):\n",
    "\n",
    "        self.video_read_fn = video_read_fn\n",
    "        self.facedet = facedet\n",
    "    \n",
    "    def process_video(self, video_path):\n",
    "        \"\"\"Convenience method for doing face extraction on a single video.\"\"\"\n",
    " \n",
    "        result = []\n",
    "    \n",
    "        target_size = self.facedet.input_size\n",
    "        \n",
    "        # 1 - get frames\n",
    "        frames = self.video_read_fn(video_path)\n",
    "        # Error? Then skip this video.\n",
    "        if frames is None: return result\n",
    "            \n",
    "            \n",
    "        # 2 - split the frames into several tiles. Resize the tiles to 128x128.\n",
    "        tiles, resize_info = self._tile_frames(frames, target_size)\n",
    "        \n",
    "        \n",
    "        # 3 - Run the face detector. The result is a list of PyTorch tensors, \n",
    "        # one for each image in the batch.\n",
    "        detections = self.facedet.predict_on_batch(tiles, apply_nms=False)\n",
    "        \n",
    "        # 3 - convert the detections from 128x128 back to the original frame size.\n",
    "        detections = self._resize_detections(detections, target_size, resize_info)\n",
    "        \n",
    "        \n",
    "        # 4 - Because we have several tiles for each frame, combine the predictions\n",
    "        # from these tiles. The result is a list of PyTorch tensors, but now one\n",
    "        # for each frame (rather than each tile).\n",
    "        num_frames = frames.shape[0]\n",
    "        frame_size = (frames.shape[2], frames.shape[1])\n",
    "        detections = self._untile_detections(num_frames, frame_size, detections)\n",
    "        \n",
    "         \n",
    "        # 5 - The same face may have been detected in multiple tiles, so filter out\n",
    "        # overlapping detections. This is done separately for each frame.\n",
    "        detections = self.facedet.nms(detections)\n",
    "        \n",
    "        \n",
    "        for i in range(len(detections)):\n",
    "            # Crop the faces out of the original frame.\n",
    "            faces = self._add_margin_to_detections(detections[i], frame_size, 0.2)\n",
    "            faces = self._crop_faces(frames[i], faces)\n",
    "\n",
    "            # Add additional information about the frame and detections.\n",
    "            scores = list(detections[i][:, 16].cpu().numpy())\n",
    "            frame_dict = { \"frame_w\": frame_size[0],\n",
    "                            \"frame_h\": frame_size[1],\n",
    "                            \"faces\": faces, \n",
    "                            \"scores\": scores }\n",
    "            result.append(frame_dict)\n",
    "        \n",
    "        \n",
    "        return result\n",
    "\n",
    "\n",
    "    def _tile_frames(self, frames, target_size):\n",
    "\n",
    "        num_frames, H, W, _ = frames.shape\n",
    "\n",
    "        # Settings for 6 overlapping windows:\n",
    "        # split_size = 720\n",
    "        # x_step = 480\n",
    "        # y_step = 360\n",
    "        # num_v = 2\n",
    "        # num_h = 3\n",
    "\n",
    "        # Settings for 2 overlapping windows:\n",
    "        # split_size = min(H, W)\n",
    "        # x_step = W - split_size\n",
    "        # y_step = H - split_size\n",
    "        # num_v = 1\n",
    "        # num_h = 2 if W > H else 1\n",
    "\n",
    "        split_size = min(H, W)\n",
    "        x_step = (W - split_size) // 2\n",
    "        y_step = (H - split_size) // 2\n",
    "        num_v = 1\n",
    "        num_h = 3 if W > H else 1\n",
    "\n",
    "        splits = np.zeros((num_frames * num_v * num_h, target_size[1], target_size[0], 3), dtype=np.uint8)\n",
    "\n",
    "        i = 0\n",
    "        for f in range(num_frames):\n",
    "            y = 0\n",
    "            for v in range(num_v):\n",
    "                x = 0\n",
    "                for h in range(num_h):\n",
    "                    crop = frames[f, y:y+split_size, x:x+split_size, :]\n",
    "                    splits[i] = cv2.resize(crop, target_size, interpolation=cv2.INTER_AREA)\n",
    "                    x += x_step\n",
    "                    i += 1\n",
    "                y += y_step\n",
    "\n",
    "        resize_info = [split_size / target_size[0], split_size / target_size[1], 0, 0]\n",
    "        return splits, resize_info\n",
    "\n",
    "    def _resize_detections(self, detections, target_size, resize_info):\n",
    "\n",
    "        projected = []\n",
    "        target_w, target_h = target_size\n",
    "        scale_w, scale_h, offset_x, offset_y = resize_info\n",
    "\n",
    "        for i in range(len(detections)):\n",
    "            detection = detections[i].clone()\n",
    "\n",
    "            # ymin, xmin, ymax, xmax\n",
    "            for k in range(2):\n",
    "                detection[:, k*2    ] = (detection[:, k*2    ] * target_h - offset_y) * scale_h\n",
    "                detection[:, k*2 + 1] = (detection[:, k*2 + 1] * target_w - offset_x) * scale_w\n",
    "\n",
    "            # keypoints are x,y\n",
    "            for k in range(2, 8):\n",
    "                detection[:, k*2    ] = (detection[:, k*2    ] * target_w - offset_x) * scale_w\n",
    "                detection[:, k*2 + 1] = (detection[:, k*2 + 1] * target_h - offset_y) * scale_h\n",
    "\n",
    "            projected.append(detection)\n",
    "\n",
    "        return projected    \n",
    "    \n",
    "    def _untile_detections(self, num_frames, frame_size, detections):\n",
    "\n",
    "        combined_detections = []\n",
    "\n",
    "        W, H = frame_size\n",
    "        split_size = min(H, W)\n",
    "        x_step = (W - split_size) // 2\n",
    "        y_step = (H - split_size) // 2\n",
    "        num_v = 1\n",
    "        num_h = 3 if W > H else 1\n",
    "\n",
    "        i = 0\n",
    "        for f in range(num_frames):\n",
    "            detections_for_frame = []\n",
    "            y = 0\n",
    "            for v in range(num_v):\n",
    "                x = 0\n",
    "                for h in range(num_h):\n",
    "                    # Adjust the coordinates based on the split positions.\n",
    "                    detection = detections[i].clone()\n",
    "                    if detection.shape[0] > 0:\n",
    "                        for k in range(2):\n",
    "                            detection[:, k*2    ] += y\n",
    "                            detection[:, k*2 + 1] += x\n",
    "                        for k in range(2, 8):\n",
    "                            detection[:, k*2    ] += x\n",
    "                            detection[:, k*2 + 1] += y\n",
    "\n",
    "                    detections_for_frame.append(detection)\n",
    "                    x += x_step\n",
    "                    i += 1\n",
    "                y += y_step\n",
    "\n",
    "            combined_detections.append(torch.cat(detections_for_frame))\n",
    "\n",
    "        return combined_detections\n",
    "    \n",
    "    def _add_margin_to_detections(self, detections, frame_size, margin=0.2):\n",
    "\n",
    "        offset = torch.round(margin * (detections[:, 2] - detections[:, 0]))\n",
    "        detections = detections.clone()\n",
    "        detections[:, 0] = torch.clamp(detections[:, 0] - offset*2, min=0)            # ymin\n",
    "        detections[:, 1] = torch.clamp(detections[:, 1] - offset, min=0)              # xmin\n",
    "        detections[:, 2] = torch.clamp(detections[:, 2] + offset, max=frame_size[1])  # ymax\n",
    "        detections[:, 3] = torch.clamp(detections[:, 3] + offset, max=frame_size[0])  # xmax\n",
    "        return detections\n",
    "    \n",
    "    def _crop_faces(self, frame, detections):\n",
    "        \"\"\"Copies the face region(s) from the given frame into a set\n",
    "        of new NumPy arrays.\n",
    "\n",
    "        Arguments:\n",
    "            frame: a NumPy array of shape (H, W, 3)\n",
    "            detections: a PyTorch tensor of shape (num_detections, 17)\n",
    "\n",
    "        Returns a list of NumPy arrays, one for each face crop. If there\n",
    "        are no faces detected for this frame, returns an empty list.\n",
    "        \"\"\"\n",
    "        faces = []\n",
    "        for i in range(len(detections)):\n",
    "            ymin, xmin, ymax, xmax = detections[i, :4].cpu().numpy().astype(np.int)\n",
    "            face = frame[ymin:ymax, xmin:xmax, :]\n",
    "            faces.append(face)\n",
    "        return faces\n",
    "\n",
    "    def remove_large_crops(self, crops, pct=0.1):\n",
    "\n",
    "        for i in range(len(crops)):\n",
    "            frame_data = crops[i]\n",
    "            video_area = frame_data[\"frame_w\"] * frame_data[\"frame_h\"]\n",
    "            faces = frame_data[\"faces\"]\n",
    "            scores = frame_data[\"scores\"]\n",
    "            new_faces = []\n",
    "            new_scores = []\n",
    "            for j in range(len(faces)):\n",
    "                face = faces[j]\n",
    "                face_H, face_W, _ = face.shape\n",
    "                face_area = face_H * face_W\n",
    "                if face_area / video_area < 0.1:\n",
    "                    new_faces.append(face)\n",
    "                    new_scores.append(scores[j])\n",
    "            frame_data[\"faces\"] = new_faces\n",
    "            frame_data[\"scores\"] = new_scores\n",
    "\n",
    "    def keep_only_best_face(self, crops):\n",
    "\n",
    "        for i in range(len(crops)):\n",
    "            frame_data = crops[i]\n",
    "            if len(frame_data[\"faces\"]) > 0:\n",
    "                frame_data[\"faces\"] = frame_data[\"faces\"][:1]\n",
    "                frame_data[\"scores\"] = frame_data[\"scores\"][:1]\n",
    "\n",
    "    # TODO: def filter_likely_false_positives(self, crops):\n",
    "    #   if only some frames have more than 1 face, it's likely a false positive\n",
    "    #   if most frames have more than 1 face, it's probably two people\n",
    "    #   so find the % of frames with > 1 face; if > 0.X, keep the two best faces\n",
    "\n",
    "    # TODO: def filter_by_score(self, crops, min_score) to remove any\n",
    "    # crops with a confidence score lower than min_score\n",
    "\n",
    "    # TODO: def sort_by_histogram(self, crops) for videos with 2 people."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames_per_vid = 64\n",
    "input_size = 224\n",
    "\n",
    "video_read_fn = lambda x: read_frames(x)\n",
    "face_extractor = FaceExtractor(video_read_fn, facedet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import Normalize\n",
    "\n",
    "mean = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.225]\n",
    "normalize_transform = Normalize(mean, std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isotropically_resize_image(img, size, resample=cv2.INTER_AREA):\n",
    "    h, w = img.shape[:2]\n",
    "    if w > h:\n",
    "        h = h * size // w\n",
    "        w = size\n",
    "    else:\n",
    "        w = w * size // h\n",
    "        h = size\n",
    "\n",
    "    resized = cv2.resize(img, (w, h), interpolation=resample)\n",
    "    return resized\n",
    "\n",
    "\n",
    "def make_square_image(img):\n",
    "    h, w = img.shape[:2]\n",
    "    size = max(h, w)\n",
    "    t = 0\n",
    "    b = size - h\n",
    "    l = 0\n",
    "    r = size - w\n",
    "    return cv2.copyMakeBorder(img, t, b, l, r, cv2.BORDER_CONSTANT, value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "\n",
    "class MyResNeXt(models.resnet.ResNet):\n",
    "    def __init__(self, training=True):\n",
    "        super(MyResNeXt, self).__init__(block=models.resnet.Bottleneck,\n",
    "                                        layers=[3, 4, 6, 3], \n",
    "                                        groups=32, \n",
    "                                        width_per_group=4)\n",
    "        self.fc = nn.Linear(2048, 1)\n",
    "        in_features = self.fc.in_features\n",
    "    \n",
    "#         self.fc = nn.Sequential(\n",
    "#             nn.BatchNorm1d(in_features),\n",
    "#             nn.Dropout(),\n",
    "#             nn.Linear(in_features, in_features//2),\n",
    "#             nn.ReLU(),\n",
    "            \n",
    "#             nn.BatchNorm1d(in_features//2),\n",
    "#             nn.Dropout(),\n",
    "#             nn.Linear(in_features//2, in_features//4),\n",
    "#             nn.ReLU(),\n",
    "            \n",
    "#             nn.BatchNorm1d(in_features//4),\n",
    "#             nn.Dropout(),\n",
    "#             nn.Linear(in_features//4, 1),\n",
    "#         )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load('../input/dfdcresnetxt2020327/best_model_.pth', map_location=gpu)\n",
    "\n",
    "model = MyResNeXt().to(gpu)\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "_ = model.eval()\n",
    "\n",
    "del checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_on_video(video_path, batch_size):\n",
    "    try:\n",
    "        # Find the faces for N frames in the video.\n",
    "        faces = face_extractor.process_video(video_path)\n",
    "\n",
    "        # Only look at one face per frame.\n",
    "        face_extractor.keep_only_best_face(faces)\n",
    "        \n",
    "        if len(faces) > 0:\n",
    "            # NOTE: When running on the CPU, the batch size must be fixed\n",
    "            # or else memory usage will blow up. (Bug in PyTorch?)\n",
    "            x = np.zeros((batch_size, input_size, input_size, 3), dtype=np.uint8)\n",
    "\n",
    "            # If we found any faces, prepare them for the model.\n",
    "            n = 0\n",
    "            for frame_data in faces:\n",
    "                for face in frame_data[\"faces\"]:\n",
    "                    # Resize to the model's required input size.\n",
    "                    # We keep the aspect ratio intact and add zero\n",
    "                    # padding if necessary.                    \n",
    "                    resized_face = isotropically_resize_image(face, input_size)\n",
    "                    resized_face = make_square_image(resized_face)\n",
    "\n",
    "                    if n < batch_size:\n",
    "                        x[n] = resized_face\n",
    "                        n += 1\n",
    "                    else:\n",
    "                        print(\"WARNING: have %d faces but batch size is %d\" % (n, batch_size))\n",
    "                    \n",
    "                    # Test time augmentation: horizontal flips.\n",
    "                    # TODO: not sure yet if this helps or not\n",
    "                    #x[n] = cv2.flip(resized_face, 1)\n",
    "                    #n += 1\n",
    "\n",
    "            if n > 0:\n",
    "                x = torch.tensor(x, device=gpu).float()\n",
    "\n",
    "                # Preprocess the images.\n",
    "                x = x.permute((0, 3, 1, 2))\n",
    "\n",
    "                for i in range(len(x)):\n",
    "                    x[i] = normalize_transform(x[i] / 255.)\n",
    "\n",
    "                # Make a prediction, then take the average.\n",
    "                with torch.no_grad():\n",
    "                    y_pred = model(x)\n",
    "                    y_pred = torch.sigmoid(y_pred.squeeze())\n",
    "                    return y_pred[:n].mean().item()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Prediction error on video %s: %s\" % (video_path, str(e)))\n",
    "\n",
    "    return 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "def predict_on_video_set(videos, num_workers):\n",
    "    def process_file(i):\n",
    "        filename = videos[i]\n",
    "        y_pred = predict_on_video(os.path.join(test_dir, filename), batch_size=frames_per_vid)\n",
    "        return y_pred\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=num_workers) as ex:\n",
    "        predictions = ex.map(process_file, range(len(videos)))\n",
    "\n",
    "    return list(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speed test\n",
    "\n",
    "The leaderboard submission must finish within 9 hours. With 4000 test videos, that is `9*60*60/4000 = 8.1` seconds per video. So if the average time per video is greater than ~8 seconds, the kernel will be too slow!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "speed_test = True  # you have to enable this manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed 24.957580 sec. Average per video: 4.991516 sec.\n"
     ]
    }
   ],
   "source": [
    "if speed_test:\n",
    "    start_time = time.time()\n",
    "    speedtest_videos = test_videos[:5]\n",
    "    predictions = predict_on_video_set(speedtest_videos, num_workers=4)\n",
    "    elapsed = time.time() - start_time\n",
    "    print(\"Elapsed %f sec. Average per video: %f sec.\" % (elapsed, elapsed / len(speedtest_videos)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make the submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = predict_on_video_set(test_videos, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df = pd.DataFrame({\"filename\": test_videos, \"label\": predictions})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f8752da1ef0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.distplot(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# post-processing\n",
    "clip (0.1, 0.9) <br>\n",
    "change 0.5 to 0.481"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clip\n",
    "submission_df['label'] = submission_df['label'].clip(0.1, 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([118.,  10.,  12.,  13.,  13.,  20.,  14.,  17.,  29., 154.]),\n",
       " array([0.1 , 0.18, 0.26, 0.34, 0.42, 0.5 , 0.58, 0.66, 0.74, 0.82, 0.9 ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAEZJJREFUeJzt3X+sZGd93/H3B29NCoXasNfE7I9cE61JFkRlcrHcRg0E54eBhHUaE63VNEvqdhXikqQkCqZUcpQK1SQVTqJQpA04XiJi4zi03gZIahy7ViJsusa/WDvGG7O1L3bYS/iRNqiQhW//mLPSdLm+M3fOzL2zD++XtLrnPPPMnI9n1589+8zMmVQVkqR2PWOzA0iSZsuil6TGWfSS1DiLXpIaZ9FLUuMseklqnEUvSY2z6CWpcSOLPsl1SY4n+dQp429O8kiSI0l+bWj8bUmOdrf98CxCS5LGt2WMOdcDvw28/+RAku8H9gAvq6qvJjmnG98N7AVeArwQ+FiS86vq62sdYOvWrbW4uDjRf4Akfau65557Pl9VC6PmjSz6qrozyeIpw28Crqmqr3Zzjnfje4Abu/HPJDkKXAh8fK1jLC4ucvjw4VFRJElDkvyvceZNukZ/PvBPk9yd5H8keUU3vg14YmjecjcmSdok4yzdPN39zgYuAl4B3JTkRUBWmbvqVdOS7Af2A+zcuXPCGJKkUSY9o18GPlQDnwC+AWztxncMzdsOPLnaA1TVgapaqqqlhYWRS0ySpAlNWvT/FXg1QJLzgTOBzwOHgL1JnpnkPGAX8IlpBJUkTWbk0k2SG4BXAVuTLANXA9cB13VvufwasK8GF7Y/kuQm4CHgBHDlqHfcSJJmK/PwxSNLS0vlu24kaX2S3FNVS6Pm+clYSWqcRS9JjbPoJalxk76PXpKasXjVhzft2Meued3Mj+EZvSQ1zqKXpMZZ9JLUOItekhpn0UtS4yx6SWqcRS9JjbPoJalxFr0kNc6il6TGWfSS1DiLXpIaZ9FLUuMseklq3MiiT3JdkuPd98OeetsvJakkW7v9JPmtJEeTPJDk5bMILUka3zhn9NcDl5w6mGQH8IPA40PDrwF2db/2A+/pH1GS1MfIoq+qO4EvrHLTtcAvA8PfLr4HeH8N3AWcleTcqSSVJE1kojX6JK8HPltV959y0zbgiaH95W5MkrRJ1v1VgkmeBbwd+KHVbl5lrFYZI8l+Bss77Ny5c70xJEljmuSM/juB84D7kxwDtgOfTPLtDM7gdwzN3Q48udqDVNWBqlqqqqWFhYUJYkiSxrHuoq+qB6vqnKparKpFBuX+8qr6K+AQ8FPdu28uAr5cVU9NN7IkaT3GeXvlDcDHgRcnWU5yxRrTPwI8BhwFfgf42amklCRNbOQafVVdPuL2xaHtAq7sH0uSNC1+MlaSGmfRS1LjLHpJapxFL0mNs+glqXEWvSQ1zqKXpMZZ9JLUOItekhpn0UtS4yx6SWqcRS9JjbPoJalxFr0kNc6il6TGWfSS1DiLXpIaZ9FLUuPG+c7Y65IcT/KpobFfT/IXSR5I8l+SnDV029uSHE3ySJIfnlVwSdJ4xjmjvx645JSxW4GXVtXLgE8DbwNIshvYC7yku89/TnLG1NJKktZtZNFX1Z3AF04Z++9VdaLbvQvY3m3vAW6sqq9W1WeAo8CFU8wrSVqnaazR/0vgo932NuCJoduWu7FvkmR/ksNJDq+srEwhhiRpNb2KPsnbgRPAB04OrTKtVrtvVR2oqqWqWlpYWOgTQ5K0hi2T3jHJPuBHgIur6mSZLwM7hqZtB56cPJ4kqa+Jij7JJcBbgVdW1VeGbjoE/H6SdwEvBHYBn+idcg2LV314lg+/pmPXvG7Tji1J4xpZ9EluAF4FbE2yDFzN4F02zwRuTQJwV1X9TFUdSXIT8BCDJZ0rq+rrswovSRptZNFX1eWrDL9vjfnvAN7RJ5QkaXr8ZKwkNc6il6TGWfSS1DiLXpIaZ9FLUuMseklqnEUvSY2z6CWpcRa9JDXOopekxln0ktQ4i16SGmfRS1LjLHpJapxFL0mNs+glqXEWvSQ1zqKXpMaNLPok1yU5nuRTQ2PPS3Jrkke7n2d340nyW0mOJnkgyctnGV6SNNo4Z/TXA5ecMnYVcFtV7QJu6/YBXgPs6n7tB94znZiSpEmNLPqquhP4winDe4CD3fZB4NKh8ffXwF3AWUnOnVZYSdL6TbpG/4Kqegqg+3lON74NeGJo3nI39k2S7E9yOMnhlZWVCWNIkkaZ9ouxWWWsVptYVQeqaqmqlhYWFqYcQ5J00qRF/7mTSzLdz+Pd+DKwY2jeduDJyeNJkvqatOgPAfu67X3ALUPjP9W9++Yi4Msnl3gkSZtjy6gJSW4AXgVsTbIMXA1cA9yU5ArgceAN3fSPAK8FjgJfAX56BpklSeswsuir6vKnueniVeYWcGXfUJKk6fGTsZLUOItekhpn0UtS4yx6SWqcRS9JjbPoJalxFr0kNc6il6TGWfSS1DiLXpIaZ9FLUuMseklqnEUvSY2z6CWpcRa9JDXOopekxln0ktQ4i16SGter6JP82yRHknwqyQ1Jvi3JeUnuTvJokg8mOXNaYSVJ6zdx0SfZBvwcsFRVLwXOAPYC7wSurapdwBeBK6YRVJI0mb5LN1uAv59kC/As4Cng1cDN3e0HgUt7HkOS1MPERV9VnwX+E/A4g4L/MnAP8KWqOtFNWwa2rXb/JPuTHE5yeGVlZdIYkqQR+izdnA3sAc4DXgg8G3jNKlNrtftX1YGqWqqqpYWFhUljSJJG6LN08wPAZ6pqpar+DvgQ8E+As7qlHIDtwJM9M0qSeuhT9I8DFyV5VpIAFwMPAbcDl3Vz9gG39IsoSeqjzxr93QxedP0k8GD3WAeAtwJvSXIUeD7wvinklCRNaMvoKU+vqq4Grj5l+DHgwj6PK0maHj8ZK0mNs+glqXEWvSQ1zqKXpMZZ9JLUOItekhpn0UtS4yx6SWqcRS9JjbPoJalxFr0kNc6il6TGWfSS1DiLXpIaZ9FLUuMseklqnEUvSY3rVfRJzkpyc5K/SPJwkn+c5HlJbk3yaPfz7GmFlSStX98z+t8E/riqvgv4R8DDwFXAbVW1C7it25ckbZKJiz7Jc4Hvo/vy76r6WlV9CdgDHOymHQQu7RtSkjS5Pmf0LwJWgN9Ncm+S9yZ5NvCCqnoKoPt5zhRySpIm1KfotwAvB95TVRcAf8s6lmmS7E9yOMnhlZWVHjEkSWvpU/TLwHJV3d3t38yg+D+X5FyA7ufx1e5cVQeqaqmqlhYWFnrEkCStZeKir6q/Ap5I8uJu6GLgIeAQsK8b2wfc0iuhJKmXLT3v/2bgA0nOBB4DfprBXx43JbkCeBx4Q89jSJJ66FX0VXUfsLTKTRf3eVxJ0vT4yVhJapxFL0mNs+glqXEWvSQ1zqKXpMZZ9JLUOItekhpn0UtS4yx6SWqcRS9JjbPoJalxFr0kNc6il6TGWfSS1DiLXpIaZ9FLUuMseklqnEUvSY3rXfRJzkhyb5I/6vbPS3J3kkeTfLD7PllJ0iaZxhn9zwMPD+2/E7i2qnYBXwSumMIxJEkT6lX0SbYDrwPe2+0HeDVwczflIHBpn2NIkvrpe0b/G8AvA9/o9p8PfKmqTnT7y8C2nseQJPUwcdEn+RHgeFXdMzy8ytR6mvvvT3I4yeGVlZVJY0iSRuhzRv+9wOuTHANuZLBk8xvAWUm2dHO2A0+udueqOlBVS1W1tLCw0COGJGktExd9Vb2tqrZX1SKwF/jTqvrnwO3AZd20fcAtvVNKkiY2i/fRvxV4S5KjDNbs3zeDY0iSxrRl9JTRquoO4I5u+zHgwmk8riSpPz8ZK0mNs+glqXEWvSQ1zqKXpMZZ9JLUOItekhpn0UtS4yx6SWqcRS9JjbPoJalxU7kEgiRNw+JVH97sCE3yjF6SGmfRS1LjLHpJapxFL0mNs+glqXEWvSQ1zqKXpMZNXPRJdiS5PcnDSY4k+flu/HlJbk3yaPfz7OnFlSStV58z+hPAL1bVdwMXAVcm2Q1cBdxWVbuA27p9SdImmbjoq+qpqvpkt/2/gYeBbcAe4GA37SBwad+QkqTJTWWNPskicAFwN/CCqnoKBn8ZAOdM4xiSpMn0vtZNkn8A/CHwC1X1N0nGvd9+YD/Azp07+8aQZmazrr9y7JrXbcpx1Z5eZ/RJ/h6Dkv9AVX2oG/5cknO7288Fjq9236o6UFVLVbW0sLDQJ4YkaQ193nUT4H3Aw1X1rqGbDgH7uu19wC2Tx5Mk9dVn6eZ7gX8BPJjkvm7s3wHXADcluQJ4HHhDv4iSpD4mLvqq+jPg6RbkL570cSVtLq8J3x4/GStJjbPoJalxFr0kNc7vjJXmlGvlmhaLXuti+UinH5duJKlxntGfhjyrlrQentFLUuM8o+/BM2tJpwPP6CWpcRa9JDXOopekxln0ktQ4i16SGmfRS1LjLHpJapxFL0mNs+glqXEzK/oklyR5JMnRJFfN6jiSpLXNpOiTnAG8G3gNsBu4PMnuWRxLkrS2WZ3RXwgcrarHquprwI3AnhkdS5K0hlkV/TbgiaH95W5MkrTBZnX1yqwyVv/fhGQ/sL/b/T9JHpnwWFuBz09431ma11wwv9nMtT7mWp+5zJV39sr1HeNMmlXRLwM7hva3A08OT6iqA8CBvgdKcriqlvo+zrTNay6Y32zmWh9zrc+3cq5ZLd38T2BXkvOSnAnsBQ7N6FiSpDXM5Iy+qk4k+TfAnwBnANdV1ZFZHEuStLaZfcNUVX0E+MisHn9I7+WfGZnXXDC/2cy1PuZan2/ZXKmq0bMkSactL4EgSY07bYp+1CUVknxfkk8mOZHksjnK9ZYkDyV5IMltScZ6O9QG5PqZJA8muS/Jn23UJ5fHvTRGksuSVJINeZfEGM/XG5OsdM/XfUn+1Tzk6ub8RPdn7EiS35+HXEmuHXquPp3kS3OSa2eS25Pc2/0/+do5yfUdXT88kOSOJNunGqCq5v4Xgxd0/xJ4EXAmcD+w+5Q5i8DLgPcDl81Rru8HntVtvwn44Jzkeu7Q9uuBP56HXN285wB3AncBS/OQC3gj8Nsb8edqnbl2AfcCZ3f758xDrlPmv5nBGzI2PReD9fA3ddu7gWNzkusPgH3d9quB35tmhtPljH7kJRWq6lhVPQB8Y85y3V5VX+l272LwmYJ5yPU3Q7vP5pQPtG1Wrs5/AH4N+L8bkGk9uTbaOLn+NfDuqvoiQFUdn5Ncwy4HbpiTXAU8t9v+h5zy+Z5NzLUbuK3bvn2V23s5XYp+Xi+psN5cVwAfnWmigbFyJbkyyV8yKNWfm4dcSS4AdlTVH21AnrFzdX68+6f1zUl2rHL7ZuQ6Hzg/yZ8nuSvJJXOSCxgsSQDnAX86J7l+BfjJJMsM3hX45jnJdT/w4932jwHPSfL8aQU4XYp+5CUVNsnYuZL8JLAE/PpME3WHW2Xsm3JV1bur6juBtwL/fuapRuRK8gzgWuAXNyDLsHGer/8GLFbVy4CPAQdnnmq8XFsYLN+8isGZ83uTnDUHuU7aC9xcVV+fYZ6Txsl1OXB9VW0HXgv8XvfnbrNz/RLwyiT3Aq8EPgucmFaA06XoR15SYZOMlSvJDwBvB15fVV+dl1xDbgQunWmigVG5ngO8FLgjyTHgIuDQBrwgO84lO/566Pfud4DvmXGmsXJ1c26pqr+rqs8AjzAo/s3OddJeNmbZBsbLdQVwE0BVfRz4NgbXwNnUXFX1ZFX9s6q6gEFXUFVfnlqCWb8QMaUXM7YAjzH4J+DJFzNe8jRzr2fjXowdmQu4gMELMbvm6fkazgP8KHB4HnKdMv8ONubF2HGer3OHtn8MuGtOcl0CHOy2tzJYInj+Zufq5r0YOEb3eZ05eb4+Cryx2/5uBoU703xj5toKPKPbfgfwq1PNsBG/AVN6sl4LfLorzbd3Y7/K4CwZ4BUM/ub8W+CvgSNzkutjwOeA+7pfh+Yk128CR7pMt69VuBuZ65S5G1L0Yz5f/7F7vu7vnq/vmpNcAd4FPAQ8COydh1zd/q8A12xEnnU8X7uBP+9+H+8DfmhOcl0GPNrNeS/wzGke30/GSlLjTpc1eknShCx6SWqcRS9JjbPoJalxFr0kNc6il6TGWfSS1DiLXpIa9/8A30Ict7hedCEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# check clip\n",
    "plt.hist(submission_df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change 0.5 to 0.481\n",
    "submission_df = submission_df.replace(0.5, 0.481)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the file\n",
    "submission_df.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aassnaulhq.mp4</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aayfryxljh.mp4</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>acazlolrpz.mp4</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>adohdulfwb.mp4</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ahjnxtiamx.mp4</td>\n",
       "      <td>0.544563</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         filename     label\n",
       "0  aassnaulhq.mp4  0.900000\n",
       "1  aayfryxljh.mp4  0.100000\n",
       "2  acazlolrpz.mp4  0.900000\n",
       "3  adohdulfwb.mp4  0.100000\n",
       "4  ahjnxtiamx.mp4  0.544563"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check submission\n",
    "df = pd.read_csv('submission.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([118.,  10.,  12.,  13.,  15.,  18.,  14.,  17.,  29., 154.]),\n",
       " array([0.1 , 0.18, 0.26, 0.34, 0.42, 0.5 , 0.58, 0.66, 0.74, 0.82, 0.9 ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(df['label'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
