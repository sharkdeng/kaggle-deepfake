{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, Sequential, load_model, save_model\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.callbacks import TensorBoard, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.applications import * \n",
    "from tensorflow.keras.utils import *\n",
    "from tensorflow.keras.optimizers import *\n",
    "\n",
    "!pip install efficientnet -q\n",
    "import efficientnet.tfkeras as efn"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../input/deepfake98493faces/outputs/metadata.csv')\n",
    "def add_prefix(p):\n",
    "    return os.path.join('../input/deepfake98493faces/outputs/', p)\n",
    "def change_label(l):\n",
    "    return ['REAL', 'FAKE'].index(l)\n",
    "df['path'] = list(map(add_prefix, df['name_path'].values))\n",
    "df['label'] = list(map(change_label, df['label'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the add_path is correct\n",
    "print(df.loc[0, 'name_path'])\n",
    "print(df.loc[0, 'path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# balance\n",
    "real_df = df[df.label==0]\n",
    "fake_df = df[df.label==1].sample(len(real_df))\n",
    "print(len(real_df), len(fake_df))\n",
    "\n",
    "# shuffle\n",
    "train_df = shuffle(pd.concat([real_df, fake_df]))\n",
    "test_df = df[~df.index.isin(train_df.index)]\n",
    "\n",
    "\n",
    "# split\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.2)\n",
    "\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "val_df = val_df.reset_index(drop=True)\n",
    "test_df = test_df.reset_index(drop=True)\n",
    "print(len(train_df), len(val_df), len(test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display one image\n",
    "def prepocess(x):\n",
    "    x = tf.io.read_file(x)\n",
    "    x = tf.image.decode_jpeg(x, channels=3)\n",
    "    print(x.shape)\n",
    "    if x.shape != (224, 224, 3):\n",
    "        x = tf.image.resize(x, [224,224])\n",
    "    x = tf.cast(x, dtype=tf.float32)/255.\n",
    "    return x\n",
    "\n",
    "img=prepocess(df.loc[0, 'path'])\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# EfficientNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    base = efn.EfficientNetB4(weights='imagenet', include_top=False, input_shape=(224, 224, 3), pooling='avg') \n",
    "    x = Dense(1)(base.output)\n",
    "    return Model(inputs=base.input, outputs=x)\n",
    "\n",
    "model_efn = build_model()\n",
    "# plot_model(model_efn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_efn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_outputs = [layer.output for layer in model_efn.layers[:16]] #前16层输出\n",
    "layer_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation_model = Model(inputs=model_efn.input, outputs=layer_outputs) #构建能够输出前16层的模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activations = activation_model.predict(tf.expand_dims(img, 0), steps=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activations[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow(activations[1][0,:,:,0], cmap='viridis') #第1卷积层的第1特征层输出\n",
    "plt.matshow(activations[1][0,:,:,1], cmap='viridis')\n",
    "plt.matshow(activations[1][0,:,:,2], cmap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_names = []\n",
    "for layer in vgg16_model.layers[:16]:\n",
    "    layer_names.append(layer.name) #特征层的名字\n",
    "\n",
    "images_per_row=16\n",
    "\n",
    "for layer_name, layer_activation in zip (layer_names[1:16], activations[1:16]):\n",
    "    n_feature = layer_activation.shape[-1] # 每层输出的特征层数\n",
    "    size = layer_activation.shape[1]  #每层的特征大小\n",
    "    n_cols = n_feature//images_per_row #特征图平铺的行数\n",
    "    display_grid = np.zeros((size*n_cols, images_per_row*size)) # 每层图片大小\n",
    "    for col in range(n_cols): #行扫描\n",
    "        for row in  range (images_per_row): #平铺每行\n",
    "            # print(layer_activation.shape)\n",
    "            # print(col*images_per_row+row)\n",
    "            channel_image = layer_activation[0,:,:,col*images_per_row+row] # 写入col*images_per_row+row特征层\n",
    "            channel_image -= channel_image.mean() #标准化处理，增加可视化效果\n",
    "            channel_image /= channel_image.std()\n",
    "            channel_image *=64\n",
    "            channel_image +=128\n",
    "            channel_image = np.clip(channel_image, 0, 255).astype('uint8')\n",
    "            # print(channel_image.shape)\n",
    "            # print(display_grid[col*size:(col+1)*size, row*size:(row+1)*size].shape)\n",
    "            display_grid[col*size:(col+1)*size, row*size:(row+1)*size] = channel_image #写入大图中\n",
    "    scale = 1./size #每组图缩放系数\n",
    "    plt.figure(figsize=(scale*display_grid.shape[1], scale*display_grid.shape[0]))\n",
    "    plt.title(layer_name)\n",
    "    plt.grid(False)\n",
    "    plt.imshow(display_grid, aspect='auto', cmap='viridis')"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = BinaryCrossentropy(from_logits=True)\n",
    "optim = Adam(learning_rate=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = tf.data.Dataset.from_tensor_slices((train_df['path'].values, train_df['label'].values)).batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_process(x, y):\n",
    "    imgs = []\n",
    "    for i in range(len(x)):\n",
    "        img = tf.io.read_file(x[i].numpy())\n",
    "        img = tf.image.decode_jpeg(img, channels=3)\n",
    "        img = tf.cast(img, dtype=tf.float32)/255.\n",
    "        imgs.append(img)\n",
    "    imgs = tf.convert_to_tensor(imgs)\n",
    "    \n",
    "    return imgs, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, y in train_ds:\n",
    "    x, y = train_process(x, y)\n",
    "    print(x.shape, y.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_on(epoch):\n",
    "    for i, (x, y) in enumerate(train_ds):\n",
    "        x, y = train_process(x, y)\n",
    "        with tf.GradientTape() as tape:\n",
    "            preds = model_efn(x)\n",
    "            loss = loss_fn(y, preds)\n",
    "        grads = tape.gradient(loss, model_efn.trainable_variables)\n",
    "        optim.apply_gradients(zip(grads, model_efn.trainable_variables))\n",
    "            \n",
    "        if i % 1 == 0:\n",
    "            print('Epoch: %d, Step: %d, Loss: %2f' % (epoch, i, loss.numpy()))\n",
    "            print(\"grads=\", grads[:12][0])\n",
    "        del grads, preds, loss\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import cuda\n",
    "cuda.select_device(0)\n",
    "cuda.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "\n",
    "def create_model_and_train( ):\n",
    "      .....\n",
    "      .....\n",
    "\n",
    "p = multiprocessing.Process(target=create_model_and_train)\n",
    "p.start()\n",
    "p.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epochs):\n",
    "    for e in range(epochs):\n",
    "        train_on(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model_efn\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
